{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "import numpy as np\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain_community.llms import HuggingFacePipeline\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pdf files in the local directory\n",
    "current_directory = os.getcwd()\n",
    "def document_loader(folder, chunk_size = 700, chunk_overlap  = 50):\n",
    "\n",
    "    loader = PyPDFDirectoryLoader(folder)\n",
    "\n",
    "    docs_before_split = loader.load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = chunk_size,\n",
    "        chunk_overlap = chunk_overlap,\n",
    "    )\n",
    "    docs_after_split = text_splitter.split_documents(docs_before_split)\n",
    "    return docs_after_split\n",
    "\n",
    "docs_after_split = document_loader(current_directory, chunk_size = 700, chunk_overlap  = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '/home/onyxia/work/RAG/CV RAZIG_Ilias_en.pdf', 'page': 0}, page_content='RAZIG Ilias   \\n \\n       | razigilias@gmail.com  | +33 07.83.74.23.94  \\n \\nEnthusiastic d ata scientist with a financial background, looking for an opportunity in data science. Eager to leverage my passion for machine \\nlearning to drive analysis at the intersection of data science and business expertise.  \\n \\nEDUCATION  \\n09/2023 – 09/2024  ▪ MS Data Science ENSAE, Institut Polytechnique de Paris  \\nMain  courses  : \\n· Deep Learning  : Models and Optimization  \\n· Reinforcement Learning  \\n· Machine Learning for NLP  \\n· Deploiement of Data Science projects  \\n· Machine Learning for portfolio management and trading  \\n· Bayesian Statistics  \\n· Advanced convex optimization  Paris , \\nFRANCE'),\n",
       " Document(metadata={'source': '/home/onyxia/work/RAG/CV RAZIG_Ilias_en.pdf', 'page': 0}, page_content='· Advanced convex optimization  Paris , \\nFRANCE  \\n09/2019 – 09/2023  ▪ Magistère Ban king and  Finance,  M2 Financial and Banking Techniques at PARIS University \\nPanthéon -Assas . Received with  high honours  (15,1/20) . \\nMain courses  : \\n· Finan cial Markets (Derivatives , Fixed Income , Asset Valuation, S tructuring ) \\n· Economics  (Macroeconomics / Microeconomics, Econometrics, Time Series ) \\n· Mathematics  (Dynamic optimization , Stochastic calculus , Rate models ) \\n· Data Science for financial markets  \\n· Quantitatives strategies for asset management  \\n· Master’s thesis  : « Use of A.I  for optimization in asset management  » Paris,  \\nFRANCE'),\n",
       " Document(metadata={'source': '/home/onyxia/work/RAG/CV RAZIG_Ilias_en.pdf', 'page': 0}, page_content='FRANCE  \\n09/2017 - 06/2020  ▪ Bachelor’s degree in Economics at PARIS University Panthéon -Assas . Received with honours.  Paris,  \\nFRANCE  \\nEXP ERIENCES  \\n05/2024 – 11/2024 ▪ Optimization  Engineer , EDF  \\n· Statistical and stochastic modelling  of temperatures and gas prices  \\n· Monte -Carlo methods  for simulation  \\n· Time Series  \\n· Machine Learning  \\n· Creation of algorithm to opti mize the margin of gas portfolio  Paris,  \\nFRANCE  \\n03/202 2 – 09/2023  ▪ Data Analyst,  Covéa Finance  \\n· Maintenance of internal financial databases using APIs (Bloomberg, Factset)  \\n· Participation on fund creation project with quantitative tools ( statistical methods , clustering  and'),\n",
       " Document(metadata={'source': '/home/onyxia/work/RAG/CV RAZIG_Ilias_en.pdf', 'page': 0}, page_content='optimi zation in Python)  \\n· Automation of reporting production and implementation of data analysis tools (Python, R)  Paris,  \\nFRANCE  \\n09/2021 – 03/2022  ▪ Data Analyst , WeeFin  \\n· ESG strategy consulting for both institutional and private investors  \\n· Support  investors  in the choice of extra -financial data solution (review an d test of the data ) \\n· Creation of ESG scoring methods and decision support tools  \\n· Presentation of analysis results  Paris,  \\nFRANCE  \\nPROJECTS  \\nSKILLS  \\nPOINTS OF INTEREST  \\n• Car and bike mechanics  • Karate , Basket -ball • Fashion, clothing design'),\n",
       " Document(metadata={'source': '/home/onyxia/work/RAG/CV RAZIG_Ilias_en.pdf', 'page': 0}, page_content='· Benchmarking LLM (llama -2) with other machine learning approaches for determining the family status of a person  \\n· Garbage detection on images with neural network (ResNet 50)  \\n· Creation of an evolving sentiment indicator of central bank speech with XGBoost  \\n· Creation of movie recommendation application by  multiple approaches (NLP, Matrix factorization)  \\n· Using an LSTM model to estimate the expected return on financial securities  \\nI.T Skills  \\n• Programming languages  :  Python , R, C++,  PostgreSQL ,  VBA  \\n• Tools and technologies  :  Git, Sickit -Learn, PyTorch, FastAPI , \\nDocker, Argo CD  Langu ages \\n• French  : fluent  \\n• English : advanced level (C2)'),\n",
       " Document(metadata={'source': '/home/onyxia/work/RAG/CV RAZIG_Ilias_en.pdf', 'page': 0}, page_content='• English : advanced level (C2)  \\n• Arabic, Spanish  : basics')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_after_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "# We load the langchain embedding model that is on hugging face\n",
    "huggingface_embeddings = HuggingFaceBgeEmbeddings(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\",\n",
    "    model_kwargs={'device':'cpu'}, \n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 documents retrieved which are relevant to the query. Display the first one:\n",
      "\n",
      "FRANCE  \n",
      "09/2017 - 06/2020  ▪ Bachelor’s degree in Economics at PARIS University Panthéon -Assas . Received with honours.  Paris,  \n",
      "FRANCE  \n",
      "EXP ERIENCES  \n",
      "05/2024 – 11/2024 ▪ Optimization  Engineer , EDF  \n",
      "· Statistical and stochastic modelling  of temperatures and gas prices  \n",
      "· Monte -Carlo methods  for simulation  \n",
      "· Time Series  \n",
      "· Machine Learning  \n",
      "· Creation of algorithm to opti mize the margin of gas portfolio  Paris,  \n",
      "FRANCE  \n",
      "03/202 2 – 09/2023  ▪ Data Analyst,  Covéa Finance  \n",
      "· Maintenance of internal financial databases using APIs (Bloomberg, Factset)  \n",
      "· Participation on fund creation project with quantitative tools ( statistical methods , clustering  and\n"
     ]
    }
   ],
   "source": [
    "vectorstore = FAISS.from_documents(docs_after_split, huggingface_embeddings)\n",
    "\n",
    "query = \"\"\"What formation has followed this candidate based on his CV ?\"\"\"  \n",
    "\n",
    "relevant_documents = vectorstore.similarity_search(query)\n",
    "print(f'There are {len(relevant_documents)} documents retrieved which are relevant to the query. Display the first one:\\n')\n",
    "print(relevant_documents[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e669331263004ac889e24581b76d1eb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b927349ff1434f4484732c047417a918",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af66de2cafc5475aa32a8975d5091482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8151c73a965d4fd1bba50070c280e938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bcaabb025c449cba7df2657117c3410",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8cfb8753abe49948a316b58726e2c9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use similarity searching algorithm and return 3 most relevant documents.\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "llm = HuggingFacePipeline(pipeline=pipeline)\n",
    "\n",
    "\n",
    "# Create a Retrieval Question Answer Chain\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "• English : advanced level (C2)  \n",
      "• Arabic, Spanish  : basics\n",
      "\n",
      "· Benchmarking LLM (llama -2) with other machine learning approaches for determining the family status of a person  \n",
      "· Garbage detection on images with neural network (ResNet 50)  \n",
      "· Creation of an evolving sentiment indicator of central bank speech with XGBoost  \n",
      "· Creation of movie recommendation application by  multiple approaches (NLP, Matrix factorization)  \n",
      "· Using an LSTM model to estimate the expected return on financial securities  \n",
      "I.T Skills  \n",
      "• Programming languages  :  Python , R, C++,  PostgreSQL ,  VBA  \n",
      "• Tools and technologies  :  Git, Sickit -Learn, PyTorch, FastAPI , \n",
      "Docker, Argo CD  Langu ages \n",
      "• French  : fluent  \n",
      "• English : advanced level (C2)\n",
      "\n",
      "RAZIG Ilias   \n",
      " \n",
      "       | razigilias@gmail.com  | +33 07.83.74.23.94  \n",
      " \n",
      "Enthusiastic d ata scientist with a financial background, looking for an opportunity in data science. Eager to leverage my passion for machine \n",
      "learning to drive analysis at the intersection of data science and business expertise.  \n",
      " \n",
      "EDUCATION  \n",
      "09/2023 – 09/2024  ▪ MS Data Science ENSAE, Institut Polytechnique de Paris  \n",
      "Main  courses  : \n",
      "· Deep Learning  : Models and Optimization  \n",
      "· Reinforcement Learning  \n",
      "· Machine Learning for NLP  \n",
      "· Deploiement of Data Science projects  \n",
      "· Machine Learning for portfolio management and trading  \n",
      "· Bayesian Statistics  \n",
      "· Advanced convex optimization  Paris , \n",
      "FRANCE\n",
      "\n",
      "Question: What can you tell me about this curriculum ?\n",
      "Helpful Answer:\n",
      "\n",
      "• The candidate has a strong background in machine learning, with experience in using various machine learning algorithms and tools such as LSTM, XGBoost, and ResNet 50.\n",
      "• The candidate has a good understanding of programming languages such as Python, R, C++, and PostgreSQL, as well as tools and technologies such as Git, Sickit-Learn, PyTorch, FastAPI, Docker, and Argo CD.\n",
      "• The candidate has a fluent command of French and advanced level proficiency in English (C2).\n",
      "• The candidate has a financial background and has applied machine learning techniques in the financial industry, including portfolio management and trading.\n",
      "• The candidate has recently completed a Master's degree in Data Science from ENSAE, Institut Polytechnique de Paris, and has gained experience in deploying data science projects.\n",
      "• The candidate is eager to leverage their passion for machine learning to drive analysis at the intersection of data science and business expertise.\n"
     ]
    }
   ],
   "source": [
    "test = qa_chain({\"query\" : \"What can you tell me about this curriculum ?\"})\n",
    "print(test['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
